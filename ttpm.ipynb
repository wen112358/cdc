{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Application\\Anaconda\\envs\\neurips\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-28 15:05:03,460 - d:\\Application\\Anaconda\\envs\\neurips\\lib\\site-packages\\castle\\backend\\__init__.py[line:36] - INFO: You can use `os.environ['CASTLE_BACKEND'] = backend` to set the backend(`pytorch` or `mindspore`).\n",
      "2023-08-28 15:05:03,532 - d:\\Application\\Anaconda\\envs\\neurips\\lib\\site-packages\\castle\\algorithms\\__init__.py[line:36] - INFO: You are using ``pytorch`` as the backend.\n"
     ]
    }
   ],
   "source": [
    "from castle.common import GraphDAG\n",
    "from castle.metrics import MetricsDAG\n",
    "from castle.datasets import DAG, Topology, THPSimulation\n",
    "from castle.algorithms import TTPM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --dataset DATASET\n",
      "ipykernel_launcher.py: error: the following arguments are required: --dataset/-d\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Application\\Anaconda\\envs\\neurips\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='argparse testing')\n",
    "parser.add_argument('--dataset', '-d', type=str, default=\"sample\", required=True, help=\"Dataset folder name\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "dataset = args.dataset\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "tp = np.load(\"data/datasets/{}/topology.npy\".format(dataset))\n",
    "ttpm = TTPM(topology_matrix=tp, max_hop=2)\n",
    "\n",
    "\n",
    "X = pd.read_csv('data/datasets/{}/alarm copy.csv'.format(dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 15:06:32,805 - d:\\Application\\Anaconda\\envs\\neurips\\lib\\site-packages\\castle\\algorithms\\ttpm\\ttpm.py[line:225] - INFO: [iter 0]: likelihood_score = -342746.061191372\n",
      "2023-08-28 15:27:27,971 - d:\\Application\\Anaconda\\envs\\neurips\\lib\\site-packages\\castle\\algorithms\\ttpm\\ttpm.py[line:225] - INFO: [iter 1]: likelihood_score = -341401.2683912085\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ttpm\u001b[39m.\u001b[39;49mlearn(X)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(ttpm\u001b[39m.\u001b[39mcausal_matrix)\n",
      "File \u001b[1;32md:\\Application\\Anaconda\\envs\\neurips\\lib\\site-packages\\castle\\algorithms\\ttpm\\ttpm.py:123\u001b[0m, in \u001b[0;36mTTPM.learn\u001b[1;34m(self, tensor, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_init(tensor)\n\u001b[0;32m    122\u001b[0m \u001b[39m# Generate causal matrix (DAG)\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m _, raw_causal_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hill_climb()\n\u001b[0;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_causal_matrix \u001b[39m=\u001b[39m Tensor(raw_causal_matrix,\n\u001b[0;32m    125\u001b[0m                              index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_matrix_names,\n\u001b[0;32m    126\u001b[0m                              columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_matrix_names)\n",
      "File \u001b[1;32md:\\Application\\Anaconda\\envs\\neurips\\lib\\site-packages\\castle\\algorithms\\ttpm\\ttpm.py:230\u001b[0m, in \u001b[0;36mTTPM._hill_climb\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m stop_tag \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[39mfor\u001b[39;00m new_edge_mat \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    229\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_one_step_change_iterator(edge_mat)):\n\u001b[1;32m--> 230\u001b[0m     new_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_em(new_edge_mat)\n\u001b[0;32m    231\u001b[0m     new_l \u001b[39m=\u001b[39m new_result[\u001b[39m0\u001b[39m]\n\u001b[0;32m    232\u001b[0m     \u001b[39m# Termination condition:\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39m#   no adjacency matrix with higher likelihood appears\u001b[39;00m\n",
      "File \u001b[1;32md:\\Application\\Anaconda\\envs\\neurips\\lib\\site-packages\\castle\\algorithms\\ttpm\\ttpm.py:345\u001b[0m, in \u001b[0;36mTTPM._em\u001b[1;34m(self, edge_mat)\u001b[0m\n\u001b[0;32m    343\u001b[0m lambda_for_i \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensor)) \u001b[39m+\u001b[39m mu[i]\n\u001b[0;32m    344\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_hop\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> 345\u001b[0m     lambda_for_i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmatmul(\n\u001b[0;32m    346\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_effect_tensor_decays[k, :],\n\u001b[0;32m    347\u001b[0m         alpha[k, :, i]\u001b[39m.\u001b[39;49mT)\n\u001b[0;32m    348\u001b[0m lambda_for_i \u001b[39m=\u001b[39m lambda_for_i[ind]\n\u001b[0;32m    349\u001b[0m x_log_lambda \u001b[39m=\u001b[39m (x_i \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog(lambda_for_i))\u001b[39m.\u001b[39msum()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ttpm.learn(X)\n",
    "print(ttpm.causal_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_causal_matrix = np.load('data/datasets/{}/causal_prior.npy'.format(dataset))\n",
    "\n",
    "GraphDAG(ttpm.causal_matrix, true_causal_matrix)\n",
    "\n",
    "ret_metrix = MetricsDAG(ttpm.causal_matrix, true_causal_matrix)\n",
    "print(ret_metrix.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
